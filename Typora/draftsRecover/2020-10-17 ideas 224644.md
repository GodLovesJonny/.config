# 20200925
## Siamese Network —— Cosine 和 Exp
根据实验分析，cosine更适用于词汇级别的语义相似度度量，而exp更适用于句子级别、段落级别的文本相似性度量。其中的原因可能是cosine仅仅计算两个向量的夹角，exp还能够保存两个向量的长度信息，而句子蕴含更多的信息。  

---

# 20200927
## 讨论后的一些点子
+ 去掉色彩（文本中/图像中），做迁移学习
+ 通过小波变换来增加维度，以替代更为随机的 1x1 conv  
+ 不同光照下的 Reid，如昏暗环境下
+ 利用强化学习方面算法，自学习 discriminative parts
+ 半监督/无监督的跨模态 Reid
+ 标记一个具有某方面针对性的新的跨模态 Reid 数据集

---

# 20200928
## 1801.01760 Sec4.3 Lalign
Cross-modal alignment on latent codes  

Q. 原本处于不同向量空间中的两个向量，经过同一映射（共享参数 w ）作用后，一定会到变换到同一向量空间中吗？  

## 2009.09343
+ Bert 生成 3 维 feature map
+ Attention（门控）加在 Vector 上，而非更早加在 feature map 上
+ Gated Block 可以尝试改成在模态之间交叉进行
+ 1080ti 上实现（160 epochs，64 batchsize）

---

# 20200929
## Cross-Modal Cross-Domain Moment Alignment Network for Person Search (CVPR 2020)
## Text-based Person Search via Attribute-aided Matching (WACV 2020)
+ 训练集与测试集以及实际应用场景的 Person ID 不同 --> Domain 迁移
+ 将描述同一个人所有句子中的名词短语作为 Attribute
+ 用 Deep CORAL loss 最小化不同模态特征向量间协方差的差异 (Reducing Modality-gap)
+ 不同的人也可能有相似的文字描述内容 (class-level dissimilarity doesn’t necessarily imply semantic dissimilarity)
+ 在 triplet loss 中根据相似度动态调整 margin
+ Attribute 作为中间模态
+ Global -> Classification; Local -> Semantic

## 1607.01719 Deep CORAL: Correlation Alignment for Deep Domain Adaptation
toread  

---

# 20201012
## 组会收获
### 知识蒸馏 -> 互学习
多个 Student 模型交替进行互相学习，从而都能获得更好的结果。  

---

# 20201013
## Dual Adversarial Network: Toward Real-world Noise Removal and Noise Generation
Triple-GAN  
Denosier R (Noise removal perspective): 通过原图 y 得到伪清晰图 x  
Generator G (Noise generation perspective): 通过清晰图 x 得到伪原图 y  
写文章的时候，考虑从数学的角度，比如贝叶斯概率的角度去分析算法。  

## 1607.01719 Deep CORAL: Correlation Alignment for Deep Domain Adaptation
很多算法假设训练集和测试集数据是独立同分布的 (i.i.d.)，但该假设实际上鲜能成立。  

CORAL method: 通过一个线性变换来对齐源分布与目标分布的二阶统计量。  
问题：依赖线性变换，不是端到端。  

本文提出一个基于非线性变换的 Deep CORAL，构建一个可导的损失函数来最小化源和目的相关性间的差异 (CORAL loss)。  

### 两个目标
#### 目标一：同时利用在预训练模型和标注源数据 (labelled source data) 上学习到的特征
方法：用预训练参数初始化网络，并在标注源数据上做 fine-tune。  

#### 目标二：希望最终学习到的特征能在目标域 (target domain) 上有好的表现
方法：用 CORAL loss 最小化源和目标域之间二阶统计量的差异。  

---

# 20201014
## Deep Mutual Learning (CVPR 2018)
### 知识蒸馏做模型压缩的依据
小网络通常和大型网络具有相同的表示容量 (same representation capacity)，但是更难训练。因此限制似乎存在于优化过程中，而不是在于网络尺寸。  

以不同的初始条件初始化两个模型。  

计算 Peer 间的 KL 散度，也可以选择对称的 Jensen-Shannon Divergence loss。  

当有 K 个模型时，可以将另外 K-1 个模型的集成作为单个 teacher 来训练一个模型。但是表现会比不集成差一些。 (reducing the posterior entropy over all classes)  

由于 KL 散度无需 label，可以将互学习方法应用于半监督学习。  

分布式训练 (distributed training) 效果更好，两个网络总是可以保持同样的迭代次数。  

While the noise-averaging property of ensembling is effective for making a correct prediction, it is actually detrimental to providing a teaching signal where the secondary class probabilities are the salient cue in the signal and having high-entropy posterior leads to more robust solutions to model training.  

做半监督学习时，可以从训练集随机选取 10%-100% 的数据作为 labelled 数据，剩余作为 unlabelled 数据。  

可用 t-SNE visualization 来可视化特征分布。  

# 20201016
## 2003.00808 A Convolutional Baseline for Person Re-Identification Using Vision and Language Descriptions
Canonical Correlation Analysis (CCA): a well-known statistical technique to find a space in which two sets of random variables are maximally correlated in the form of their linear combinations.  

## 1711.06420 Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models
交叉模态生成图像和文本  
文本生成：encoder + decoder (先 XE loss，再 XE loss + RL loss)  
图像生成：GAN (直接用 tl 生成会受限于数据量，引入基于 tl 做高斯采样的 tc 用于生成) 

两个作为生成输入的向量参与匹配。  

## 0094 Cross-Modality Person Re-Identification with Generative Adversarial Training (2018 IJCAI)
RGB <==> IR  

ID loss + triplet loss + 模态来源判断 (nothing new)  

模型图画法比较简洁，可以学习一下。  

## Deep Supervised Cross-modal Retrieval (CVPR 2019)
从不同模态得到的 vector 距离最小化。  

## 1710.05106 CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning
同模态重构特征向量  
### 两种 discriminator
inter-modality discriminator: 判断所生成的特征来自哪种模态（ASPD 用过）  
intra-modality discriminator: 区分原向量和重构生成的向量  

original representation + common representation + reconstruction representation  

### 一个可行性有待商榷的想法
维护一个文本池，通过文本相似去检索到相似的文本，用检索到的文本和源文本一同用于图像检索。  

# 20201017
## 点子：结合多粒度的跨模态重构
+ sigmoid(phrase matrix @ global visual vector) * global visual vector => reconstructed global visual vector
+ sigmoid(local visual matrix @ sentence vector) * sentence vector => reconstructed sentence vector

## Learning Cross-Modal Embeddings With Adversarial Networks for Cooking Recipes and Food Images (CVPR 2019) 
菜谱 <==> 食物图像 (图文检索)  

模态间多对一的关系 (many-to-one relationship)  
